{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e27204-073c-480d-91aa-568f48774878",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\angsp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\angsp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\utils\\hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb13a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "teacher_path = \"./model_final_taskA\"\n",
    "base_student_path = \"google/flan-t5-small\"\n",
    "studentRB_path = \"./studentRBKD_taskA\"\n",
    "studentFB_path = \"./studentFBKD_taskA\"\n",
    "studentRelB_path = \"./studentRelBKD_taskA\"  \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(teacher_path)\n",
    "\n",
    "teacher_model = AutoModelForSeq2SeqLM.from_pretrained(teacher_path).to(device)\n",
    "base_student_model = AutoModelForSeq2SeqLM.from_pretrained(base_student_path).to(device)\n",
    "studentRB_model = AutoModelForSeq2SeqLM.from_pretrained(studentRB_path).to(device)\n",
    "studentFB_model = AutoModelForSeq2SeqLM.from_pretrained(studentFB_path).to(device)\n",
    "studentRelB_model = AutoModelForSeq2SeqLM.from_pretrained(studentRelB_path).to(device)\n",
    "\n",
    "\n",
    "def generate_response(model, sentence):\n",
    "    prompt = (\n",
    "    \"In exactly 1-2 sentences, identify the specific words or phrases that make the text sarcastic \"\n",
    "    \"and explain how they create the sarcastic effect. \"\n",
    "    \"Focus only on observable linguistic elements without adding interpretation beyond what's directly evident in the text.\\n\\n\"\n",
    "    f\"Sentence: \\\"{sentence}\\\"\"\n",
    ")\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=80,\n",
    "        do_sample=True,\n",
    "        temperature=2.3,      \n",
    "        top_p=0.6,         \n",
    "        top_k=60,\n",
    "        num_beams=10,          \n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.4, \n",
    "        length_penalty=1.0,\n",
    "    )\n",
    "\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    text = re.sub(r\"^(Explanation|Answer|Response)\\s*:\\s*\", \"\", text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "\n",
    "sentences = [\n",
    "    \"Yay my shoe broke!\",\n",
    "    \"If the shooter shouldn't have been able to get a gun, the solution is obviously more guns, right? <URL>\",\n",
    "    \"Complain to the cellular company for having monopolistic dataplans and ask for an unlimited plan\",\n",
    "    \"Wonderful, traffic is even worse than yesterday!\",\n",
    "    \"I'm so sorry I can't read sarcasm over the internet\",\n",
    "    \"Slept horrible last night / I feel like crap and now I get to go sit in classes all day. Hurray! idontwannagoback\",\n",
    "    \"I'm sure a homeless shelter as a permanent address and phone number looks great on a resume to prospective employers.\",\n",
    "    \"Trains are delayed on both directions. Instead of seeing people rushing to take the bus or cab, they were taking pictures. Haha..\",\n",
    "    \"This guy gets a gold star for such excellent parking in the handicap lot!\",\n",
    "    \"Crying before I go into work... This is going to be a great night. #Sarcasm #WishItWasTrue\",\n",
    "    \"In a cab on the way home from the airport. What a long day. Work tomorrow is going to be AMAZING. Should be home by 3AM.\",\n",
    "    \"hey <user> thanks for making it easy for me to take my music with me . # ihateyourupdates\",\n",
    "    \"It could confuse your muscles and make muscle grow in places where you didn't actually work out.\",\n",
    "    \"Yay, 2-hour traffic for a 10-minute errand. Exactly what I needed ðŸ™ƒ\",\n",
    "    \"How else will we feel superior if not by our amazing taste in phones?\",\n",
    "    \"Received a compliment today that I look very relaxed. If only this person knew just how much effort it takes to look this relaxed.\",\n",
    "    \"My phone dying at 5% is the highlight of my day.\",\n",
    "    \"overweight man repeatedly introduced to overweight woman at party\",\n",
    "    \"How dare you type out Obama's name and not praise him you racist\",\n",
    "    \"No, it's perfectly safe for nurses to shove pills in your mouth without any education\",\n",
    "    \"Great, another inspirational quote on LinkedIn. Just what I needed.\",\n",
    "    \"even aside from the blatant misogyny, this is great because we have so much space in our prisons!\",\n",
    "    \"DSA4213 is sooo easy even my grandma can score A+\"\n",
    "    \"I have never felt more alive than during DSA4213 finetuning, nothing like a few CUDA OOMs to keep the adrenaline going.\",\n",
    "    \"I love how DSA4213 keeps me humble, every single assignment and quizzes\",\n",
    "    \"DSA4213 is not that hard, I just needed 4 GPUs and divine intervention\"\n",
    "]\n",
    "\n",
    "for s in sentences:\n",
    "    teacher_out = generate_response(teacher_model, s)\n",
    "    base_out = generate_response(base_student_model, s)\n",
    "    rb_out = generate_response(studentRB_model, s)\n",
    "    fb_out = generate_response(studentFB_model, s)\n",
    "    relb_out = generate_response(studentRelB_model, s)\n",
    "\n",
    "    print(f\"\\n Sentence: {s}\")\n",
    "    print(f\"Teacher (Flan-T5-base):   {teacher_out}\")\n",
    "    print(f\"Base Student (T5-small):  {base_out}\")\n",
    "    print(f\"RBKD Student:             {rb_out}\")\n",
    "    print(f\"FBKD Student:             {fb_out}\")\n",
    "    print(f\"RelBKD Student:           {relb_out}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b23e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_path = \"./model_final_taskB\"\n",
    "base_student_path = \"./model_final_dualtask\"\n",
    "studentRB_path = \"./studentRBKD_taskB\"\n",
    "studentFB_path = \"./studentFBKD_taskB\"\n",
    "studentRelB_path = \"./studentRelBKD_taskB\"   \n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(teacher_path)\n",
    "\n",
    "teacher_model = AutoModelForSeq2SeqLM.from_pretrained(teacher_path).to(device)\n",
    "base_student_model = AutoModelForSeq2SeqLM.from_pretrained(base_student_path).to(device)\n",
    "studentRB_model = AutoModelForSeq2SeqLM.from_pretrained(studentRB_path).to(device)\n",
    "studentFB_model = AutoModelForSeq2SeqLM.from_pretrained(studentFB_path).to(device)\n",
    "studentRelB_model = AutoModelForSeq2SeqLM.from_pretrained(studentRelB_path).to(device)\n",
    "\n",
    "\n",
    "def generate_response(model, sentence):\n",
    "    prompt = (\n",
    "        \"In exactly 1-2 sentences, explain what the speaker actually means by removing the sarcasm \"\n",
    "        \"and stating their true intended message directly. \"\n",
    "        \"Focus on the genuine sentiment or opinion being expressed beneath the sarcastic language.\\n\\n\"\n",
    "        f\"Sentence: \\\"{sentence}\\\"\\n\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=80,\n",
    "        do_sample=True,\n",
    "        temperature=0.01,      \n",
    "        top_p=0.6,            \n",
    "        top_k=60,\n",
    "        num_beams=10,           \n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.4, \n",
    "        length_penalty=1.0,\n",
    "    )\n",
    "\n",
    "\n",
    "    text = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    text = re.sub(r\"^(Explanation|Answer|Response)\\s*:\\s*\", \"\", text, flags=re.IGNORECASE)\n",
    "    return text\n",
    "\n",
    "\n",
    "sentences = [\n",
    "    \"Yay my shoe broke!\",\n",
    "    \"If the shooter shouldn't have been able to get a gun, the solution is obviously more guns, right? <URL>\",\n",
    "    \"Complain to the cellular company for having monopolistic dataplans and ask for an unlimited plan\",\n",
    "    \"Wonderful, traffic is even worse than yesterday!\",\n",
    "    \"I'm so sorry I can't read sarcasm over the internet\",\n",
    "    \"Slept horrible last night / I feel like crap and now I get to go sit in classes all day. Hurray! idontwannagoback\",\n",
    "    \"I'm sure a homeless shelter as a permanent address and phone number looks great on a resume to prospective employers.\",\n",
    "    \"Crying before I go into work... This is going to be a great night. #Sarcasm #WishItWasTrue\",\n",
    "    \"In a cab on the way home from the airport. What a long day. Work tomorrow is going to be AMAZING. Should be home by 3AM.\",\n",
    "    \"hey <user> thanks for making it easy for me to take my music with me . # ihateyourupdates\",\n",
    "    \"It could confuse your muscles and make muscle grow in places where you didn't actually work out.\",\n",
    "    \"Yay, 2-hour traffic for a 10-minute errand. Exactly what I needed ðŸ™ƒ\",\n",
    "    \"This guy gets a gold star for such excellent parking in the handicap lot!\",\n",
    "    \"How else will we feel superior if not by our amazing taste in phones?\",\n",
    "    \"Received a compliment today that I look very relaxed. If only this person knew just how much effort it takes to look this relaxed.\",\n",
    "    \"My phone dying at 5% is the highlight of my day.\",\n",
    "    \"overweight man repeatedly introduced to overweight woman at party\",\n",
    "    \"How dare you type out Obama's name and not praise him you racist\",\n",
    "    \"No, it's perfectly safe for nurses to shove pills in your mouth without any education\",\n",
    "    \"Great, another inspirational quote on LinkedIn. Just what I needed.\",\n",
    "    \"even aside from the blatant misogyny, this is great because we have so much space in our prisons!\",\n",
    "    \"DSA4213 is sooo easy even my grandma can score A+\"\n",
    "    \"Trains are delayed on both directions. Instead of seeing people rushing to take the bus or cab, they were taking pictures. Haha..\",\n",
    "    \"I have never felt more alive than during DSA4213 finetuning, nothing like a few CUDA OOMs to keep the adrenaline going.\",\n",
    "    \"I love how DSA4213 keeps me humble, every single assignment and quizzes\",\n",
    "    \"DSA4213 is not that hard, I just needed 4 GPUs and divine intervention\"\n",
    "]\n",
    "\n",
    "\n",
    "for s in sentences:\n",
    "    teacher_out = generate_response(teacher_model, s)\n",
    "    base_out = generate_response(base_student_model, s)\n",
    "    rb_out = generate_response(studentRB_model, s)\n",
    "    fb_out = generate_response(studentFB_model, s)\n",
    "    relb_out = generate_response(studentRelB_model, s)\n",
    "\n",
    "    print(f\"\\n Sentence: {s}\")\n",
    "    print(f\"Teacher (Flan-T5-base):   {teacher_out}\")\n",
    "    print(f\"Base Student (T5-small):  {base_out}\")\n",
    "    print(f\"RBKD Student:             {rb_out}\")\n",
    "    print(f\"FBKD Student:             {fb_out}\")\n",
    "    print(f\"RelBKD Student:           {relb_out}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
