{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_m0046uK4xV",
        "outputId": "e21888f4-4648-4e0a-9e59-47a26078d502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m324.4/324.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.1 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.6.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install -q transformers==4.44.2 peft==0.12.0 datasets==2.21.0 optuna==4.0.0 scikit-learn==1.5.1 accelerate==0.34.2\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Wu2x0WULDLh",
        "outputId": "9622c8c5-a05b-4b8e-d4d4-222bd73f5e6f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports and setup\n",
        "import os, time, random, numpy as np, pandas as pd, torch, optuna\n",
        "from pathlib import Path\n",
        "\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix, classification_report\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForSequenceClassification,\n",
        "    TrainingArguments, Trainer, set_seed\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n"
      ],
      "metadata": {
        "id": "WTjnIltILDyU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== DISTILBERT MODEL CONFIGURATION ====\n",
        "MODEL_ID = \"distilbert-base-uncased\"\n",
        "# ========================================\n",
        "\n",
        "SEED = 4213\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available(): torch.cuda.manual_seed_all(SEED)\n",
        "set_seed(SEED)\n",
        "\n",
        "MAX_LEN    = 256\n",
        "TRAIN_BS   = 16\n",
        "EVAL_BS    = 32\n",
        "OUTPUT_DIR = Path(f\"outputs/{MODEL_ID.replace('/', '_')}_lora_optuna\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "Kuh3rbS7LKVy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and prepare data\n",
        "df = pd.read_csv(\"combine_data_clean.csv\", usecols=[\"text\", \"is_sarcastic\"]).dropna()\n",
        "df[\"is_sarcastic\"] = df[\"is_sarcastic\"].astype(int)\n",
        "\n",
        "train_df, tmp_df = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df[\"is_sarcastic\"])\n",
        "val_df,   test_df = train_test_split(tmp_df, test_size=0.5, random_state=SEED, stratify=tmp_df[\"is_sarcastic\"])\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
        "val_ds   = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
        "test_ds  = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
        "\n",
        "def tokenize(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=MAX_LEN)\n",
        "\n",
        "train_tok = train_ds.map(tokenize, batched=True)\n",
        "val_tok   = val_ds.map(tokenize, batched=True)\n",
        "test_tok  = test_ds.map(tokenize, batched=True)\n",
        "\n",
        "cols = [\"input_ids\", \"attention_mask\", \"label\"]\n",
        "train_tok = train_tok.rename_column(\"is_sarcastic\", \"label\").with_format(\"torch\", columns=cols)\n",
        "val_tok   = val_tok.rename_column(\"is_sarcastic\", \"label\").with_format(\"torch\", columns=cols)\n",
        "test_tok  = test_tok.rename_column(\"is_sarcastic\", \"label\").with_format(\"torch\", columns=cols)\n",
        "\n",
        "print(f\"Train={len(train_tok)}  Val={len(val_tok)}  Test={len(test_tok)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422,
          "referenced_widgets": [
            "7bb10db0e0004be28c2fb799fa0c16e2",
            "6e9e2b0f29124e389ea942ce8ab567a6",
            "314796ec3e5e47f6845bc06bf8583527",
            "f0346d591875452f8859607b6fa11dc5",
            "ca54c391d5c74a02bf2bd1cab401862a",
            "4a8ffbfdcfc847b7a16c22c401f8b8b8",
            "7cb3eee2334f483b9ad363cce0511035",
            "120935b33eb64420b54e70e2eb9ed526",
            "c357672217b348af82bd563717cc632b",
            "afa2381017aa4641ad797f0049959556",
            "f8ff155163ff4f93bf37662e571374fd",
            "c798213342054d6b973d9203dee8fa32",
            "b8c5cb1348b7409daad1b4c673312aef",
            "211552a090b74d79bc1ad1d490ffb377",
            "954f035dac9640b58579dcb38b0545a0",
            "1a66846ecbec40bba2bdc04a96595562",
            "5ac3219d78454e54a1eb8fe6e0df72ea",
            "08ac749a61b042159dfa9434fe0849b4",
            "95682bf10f3347649fc5635d1cffb17d",
            "86c71578ab6448f29641d559a2ac66b0",
            "a1894e4246db4d01950ddde0666a8866",
            "045df6642bbe4dd49aa01580b749ccf8",
            "372cc549f72b422fa44c1d7bc335342a",
            "83e5e425a90742cfa0eb09caf0b954f0",
            "859807956b8f4609b5493d8e32eb7b9a",
            "362f1cac58c9484791160caf7167bc8c",
            "04459b86470444e894606977f695691d",
            "3cce9939dada4554bad54431c3d6d72e",
            "8cb473d3e9774330a639da27e8dbf69b",
            "c27d7d08d9c74b3099625aa3ce30283d",
            "38038ff2e5a2479f975ba4e5be997f4d",
            "bb5e1c6d0d4b477fbb547078ad5b5b6e",
            "bbec7f9d0d35454bb18a02eb0a87bc7a",
            "950949b847314b70b89f9c57e04d3832",
            "d2417834a5914200acd6387a7e43d8a8",
            "583bbd0962fd4c8698ed1d9fdadec654",
            "6a04ad68684d46eba20cc6c96595d93a",
            "ce2b3234301d4acfba726b7f9c7f8c76",
            "dfb1c35ac00c40c7a59295312f22502b",
            "48d0a08a550341febf3d0634f1516388",
            "ff03e3950c084ba2816382ef52cdcbf1",
            "3bd2fd53a63647268b88fe7f5a94a77c",
            "4756ab1b46cf471eb5bc807ac7cefeaa",
            "1d034729824643feb3876a461c997b42",
            "b05040c433e446a6985afbb35a961cb2",
            "7dc2005ca5d14f31b312fae7b4e09704",
            "c2b828e254e8414bb68945435ee86ae8",
            "9f3ebaf2a8d1438aad1940301938bcf0",
            "02914678854149db85af27dbcd8b9be3",
            "6647541e74e5475db88fe65b0732445b",
            "76bef47eef644442ba61da7e2dec78df",
            "f9a4771c208a40649488dad7bcaca1f8",
            "697a535b6468432e867eb4c0859d14ff",
            "3cf02af6a29b4e23821a48cea6e02fc6",
            "397561a971f646d09bec818c757ee9f7",
            "bd5e8719ece647429b16acc9a213b5af",
            "b57bf3447ac040cda51bdaa3407b5aba",
            "2854af9dd1164cd8bf24d56aae70a613",
            "50fb77befca74b7c9c7118d945e43ae7",
            "b5038f20bc384c45a17076430d14290f",
            "b3711d9c6bcb4c59b17d6d29da2aeeea",
            "dd362886120d4d88abc5f22fdc8dbfc3",
            "2522e8974df84ce29a166e57af786215",
            "2cca0c66c3894fb1830844d5db512238",
            "8d05838785b944d7a0e895b3c09c0da1",
            "27a4c7a3181b4820ab4c57cbfeb9bf0a",
            "86325172dae24965af438e7a7fb5242e",
            "9da25e34033f43e4b144d90acd38e7df",
            "9cb48395fcb94add8de82d4e0c519816",
            "eb6afa8a4afa49ffb3c6396d98473221",
            "673948d46b1e412086f41c806955e3fe",
            "bcb6c18801564814b37ee0558258a6ee",
            "c312fab1c0bc4e6b8b42b5b8fd5a3c52",
            "998a2e0775d440bc8cddcb04220e8104",
            "6561407b373141a5af60b02ea9111355",
            "9450354de9b44155b798d445fb9c6ed0",
            "6f56437e9d7d40ae89106d77fd906430"
          ]
        },
        "id": "Uzsmkds8LK7j",
        "outputId": "77da5464-e7b2-41c4-cb56-f3526ab6e9fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bb10db0e0004be28c2fb799fa0c16e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c798213342054d6b973d9203dee8fa32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "372cc549f72b422fa44c1d7bc335342a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "950949b847314b70b89f9c57e04d3832"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/178118 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b05040c433e446a6985afbb35a961cb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/22265 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd5e8719ece647429b16acc9a213b5af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/22265 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "86325172dae24965af438e7a7fb5242e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train=178118  Val=22265  Test=22265\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    _, _, f1w, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\", zero_division=0)\n",
        "\n",
        "    exps = np.exp(logits - logits.max(axis=1, keepdims=True))\n",
        "    probs = exps / exps.sum(axis=1, keepdims=True)\n",
        "    pos = probs[:, 1] if probs.shape[1] == 2 else np.zeros_like(labels, dtype=float)\n",
        "    try:\n",
        "        auc = roc_auc_score(labels, pos)\n",
        "    except ValueError:\n",
        "        auc = float(\"nan\")\n",
        "    return {\"accuracy\": acc, \"f1_weighted\": f1w, \"roc_auc\": auc}\n"
      ],
      "metadata": {
        "id": "LCZOUZDHLOj5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function with DistilBERT-specific LoRA config\n",
        "def train_eval_once(r, alpha, dropout, lr, num_epochs, out_dir):\n",
        "    base = AutoModelForSequenceClassification.from_pretrained(MODEL_ID, num_labels=2)\n",
        "\n",
        "    # DistilBERT uses q_lin, k_lin, v_lin instead of query, key, value\n",
        "    lora_cfg = LoraConfig(\n",
        "        task_type=TaskType.SEQ_CLS,\n",
        "        r=r, lora_alpha=alpha, lora_dropout=dropout,\n",
        "        target_modules=[\"q_lin\", \"k_lin\", \"v_lin\"],  # DistilBERT attention modules\n",
        "        bias=\"none\"\n",
        "    )\n",
        "    model = get_peft_model(base, lora_cfg)\n",
        "\n",
        "    args = TrainingArguments(\n",
        "        output_dir=str(out_dir),\n",
        "        per_device_train_batch_size=TRAIN_BS,\n",
        "        per_device_eval_batch_size=EVAL_BS,\n",
        "        learning_rate=lr,\n",
        "        num_train_epochs=num_epochs,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",\n",
        "        logging_strategy=\"no\",\n",
        "        report_to=\"none\",\n",
        "        seed=SEED,\n",
        "        fp16=torch.cuda.is_available(),\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=args,\n",
        "        train_dataset=train_tok,\n",
        "        eval_dataset=val_tok,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "    trainer.train()\n",
        "    val_metrics = trainer.evaluate()\n",
        "    return val_metrics, trainer"
      ],
      "metadata": {
        "id": "OOVbvTWsLTiH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter tuning\n",
        "def tune(n_trials=6):\n",
        "    def objective(trial):\n",
        "        r       = trial.suggest_categorical(\"r\", [4, 8, 16])\n",
        "        alpha   = trial.suggest_categorical(\"alpha\", [16, 32, 64])\n",
        "        dropout = trial.suggest_float(\"dropout\", 0.0, 0.2, step=0.1)\n",
        "        lr      = trial.suggest_float(\"lr\", 5e-6, 2e-4, log=True)\n",
        "\n",
        "        metrics, _ = train_eval_once(\n",
        "            r=r, alpha=alpha, dropout=dropout, lr=lr,\n",
        "            num_epochs=1,\n",
        "            out_dir=OUTPUT_DIR / f\"tune_t{trial.number}\"\n",
        "        )\n",
        "        return metrics[\"eval_f1_weighted\"]\n",
        "\n",
        "    study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=SEED))\n",
        "    t0 = time.time()\n",
        "    study.optimize(objective, n_trials=n_trials, show_progress_bar=False)\n",
        "    tune_time_sec = time.time() - t0\n",
        "\n",
        "    bp = study.best_params\n",
        "    best = {\"r\": int(bp[\"r\"]), \"alpha\": int(bp[\"alpha\"]), \"dropout\": float(bp[\"dropout\"]), \"lr\": float(bp[\"lr\"])}\n",
        "    return best, study.best_value, tune_time_sec\n",
        "\n",
        "# Run tuning\n",
        "best_params, best_f1, tune_time_sec = tune(n_trials=6)\n",
        "print(\"Best params:\", best_params, \" | tuning F1 (val): {:.4f}\".format(best_f1))\n",
        "print(\"Tuning time: {:.2f} min\".format(tune_time_sec/60))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "806c13d32d86429b8f6484e07e72dbea",
            "7a37db0afbc44c66b235a4ffa24d73f0",
            "e6a43c84cce24818a41bac30ecd62d46",
            "fbf4dbb51ebe4efbb2ffe36c26c3b542",
            "80f0e6c7a441495193d85fa74977fd58",
            "c7389aed075147dda7665e2926a7dd4b",
            "f9dbd59e4a4b4111af9c080b5e8c5753",
            "bdff16a3f5df49819e466f7e5b7d491c",
            "d5bd9ee454bd441dbc6dbcbb86bdd0a3",
            "ae7f31b7c12f480d939e9e13c51ba32a",
            "2771e3c11fe74464a1b46d50a698827b"
          ]
        },
        "id": "wHYEP-bOLZPa",
        "outputId": "9cc6e55a-ee9e-493c-c2b0-c0c668505e20"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-21 05:22:01,237] A new study created in memory with name: no-name-1c254136-c026-442a-a07b-3e04e6dbee62\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "806c13d32d86429b8f6484e07e72dbea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11133' max='11133' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11133/11133 20:33, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.408927</td>\n",
              "      <td>0.796587</td>\n",
              "      <td>0.796774</td>\n",
              "      <td>0.888816</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='696' max='696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [696/696 00:55]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-21 05:43:41,234] Trial 0 finished with value: 0.7967739839749697 and parameters: {'r': 16, 'alpha': 16, 'dropout': 0.2, 'lr': 5.880790798056653e-05}. Best is trial 0 with value: 0.7967739839749697.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11133' max='11133' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11133/11133 20:37, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.378814</td>\n",
              "      <td>0.813160</td>\n",
              "      <td>0.813427</td>\n",
              "      <td>0.906419</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='696' max='696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [696/696 00:55]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-21 06:05:15,267] Trial 1 finished with value: 0.8134270716109687 and parameters: {'r': 4, 'alpha': 32, 'dropout': 0.1, 'lr': 0.00011435613382670692}. Best is trial 1 with value: 0.8134270716109687.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11133' max='11133' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11133/11133 20:31, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.409885</td>\n",
              "      <td>0.797395</td>\n",
              "      <td>0.797514</td>\n",
              "      <td>0.888916</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='696' max='696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [696/696 00:55]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-21 06:26:42,593] Trial 2 finished with value: 0.7975143926571134 and parameters: {'r': 8, 'alpha': 32, 'dropout': 0.1, 'lr': 4.5344698093739294e-05}. Best is trial 1 with value: 0.8134270716109687.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11133' max='11133' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11133/11133 19:43, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.440171</td>\n",
              "      <td>0.778127</td>\n",
              "      <td>0.778176</td>\n",
              "      <td>0.870149</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='696' max='696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [696/696 00:55]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-21 06:47:22,891] Trial 3 finished with value: 0.7781762568838727 and parameters: {'r': 4, 'alpha': 16, 'dropout': 0.0, 'lr': 3.5933204300472105e-05}. Best is trial 1 with value: 0.8134270716109687.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11133' max='11133' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11133/11133 20:32, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.453516</td>\n",
              "      <td>0.771480</td>\n",
              "      <td>0.771449</td>\n",
              "      <td>0.861387</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='696' max='696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [696/696 00:55]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-21 07:08:52,380] Trial 4 finished with value: 0.7714486000500093 and parameters: {'r': 4, 'alpha': 32, 'dropout': 0.2, 'lr': 2.385613450617807e-05}. Best is trial 1 with value: 0.8134270716109687.\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11133' max='11133' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11133/11133 19:46, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.380744</td>\n",
              "      <td>0.810420</td>\n",
              "      <td>0.810712</td>\n",
              "      <td>0.905492</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='696' max='696' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [696/696 00:55]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-10-21 07:29:35,708] Trial 5 finished with value: 0.8107122125445152 and parameters: {'r': 4, 'alpha': 32, 'dropout': 0.0, 'lr': 0.00010007286900120292}. Best is trial 1 with value: 0.8134270716109687.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best params: {'r': 4, 'alpha': 32, 'dropout': 0.1, 'lr': 0.00011435613382670692}  | tuning F1 (val): 0.8134\n",
            "Tuning time: 127.57 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final training\n",
        "t1 = time.time()\n",
        "val_metrics, trainer = train_eval_once(\n",
        "    **best_params,\n",
        "    num_epochs=2,\n",
        "    out_dir=OUTPUT_DIR / \"final\"\n",
        ")\n",
        "train_time_sec = time.time() - t1\n",
        "\n",
        "# Test evaluation\n",
        "pred_test = trainer.predict(test_tok)\n",
        "test_metrics = compute_metrics((pred_test.predictions, pred_test.label_ids))\n",
        "\n",
        "summary = pd.DataFrame([{\n",
        "    \"model_id\": MODEL_ID,\n",
        "    \"best_params\": best_params,\n",
        "    \"tuning_time_min\": round(tune_time_sec/60, 2),\n",
        "    \"final_train_time_min\": round(train_time_sec/60, 2),\n",
        "    \"val_accuracy\": float(val_metrics[\"eval_accuracy\"]),\n",
        "    \"val_f1_weighted\": float(val_metrics[\"eval_f1_weighted\"]),\n",
        "    \"val_roc_auc\": float(val_metrics[\"eval_roc_auc\"]),\n",
        "    \"test_accuracy\": float(test_metrics[\"accuracy\"]),\n",
        "    \"test_f1_weighted\": float(test_metrics[\"f1_weighted\"]),\n",
        "    \"test_roc_auc\": float(test_metrics[\"roc_auc\"]),\n",
        "}])\n",
        "\n",
        "print(\"\\n=== RESULTS SUMMARY ===\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "umsYVXMwLfxs",
        "outputId": "460c1f4e-4f2d-47e6-eb45-473b66dff133"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.12/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22266' max='22266' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [22266/22266 41:04, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1 Weighted</th>\n",
              "      <th>Roc Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.370674</td>\n",
              "      <td>0.821289</td>\n",
              "      <td>0.821505</td>\n",
              "      <td>0.912139</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.359703</td>\n",
              "      <td>0.825556</td>\n",
              "      <td>0.825897</td>\n",
              "      <td>0.917937</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== RESULTS SUMMARY ===\n",
            "                  model_id                                        best_params  \\\n",
            "0  distilbert-base-uncased  {'r': 4, 'alpha': 32, 'dropout': 0.1, 'lr': 0....   \n",
            "\n",
            "   tuning_time_min  final_train_time_min  val_accuracy  val_f1_weighted  \\\n",
            "0           127.57                 42.01      0.825556         0.825897   \n",
            "\n",
            "   val_roc_auc  test_accuracy  test_f1_weighted  test_roc_auc  \n",
            "0     0.917937       0.830002          0.830344      0.920484  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Confusion matrix and classification report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_true = pred_test.label_ids\n",
        "y_pred = pred_test.predictions.argmax(-1)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"\\nConfusion Matrix (test):\\n\", cm)\n",
        "print(\"\\nClassification Report (test):\")\n",
        "print(classification_report(y_true, y_pred, digits=4))\n",
        "\n",
        "cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
        "\n",
        "plt.figure(figsize=(4.5, 4))\n",
        "plt.imshow(cm_norm, interpolation='nearest')\n",
        "plt.title('Normalized Confusion Matrix (Test) - DistilBERT')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.xticks([0,1], ['0','1'])\n",
        "plt.yticks([0,1], ['0','1'])\n",
        "for i in range(cm_norm.shape[0]):\n",
        "    for j in range(cm_norm.shape[1]):\n",
        "        plt.text(j, i, f\"{cm_norm[i, j]:.2f}\", ha=\"center\", va=\"center\")\n",
        "plt.colorbar()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "42BO54vCLieV",
        "outputId": "15143ec2-305f-40d8-86b9-f95b68684a90"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Confusion Matrix (test):\n",
            " [[8580 1516]\n",
            " [2269 9900]]\n",
            "\n",
            "Classification Report (test):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7909    0.8498    0.8193     10096\n",
            "           1     0.8672    0.8135    0.8395     12169\n",
            "\n",
            "    accuracy                         0.8300     22265\n",
            "   macro avg     0.8290    0.8317    0.8294     22265\n",
            "weighted avg     0.8326    0.8300    0.8303     22265\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 450x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save adapter\n",
        "adapter_dir = OUTPUT_DIR / \"lora_adapter\"\n",
        "trainer.model.save_pretrained(str(adapter_dir))\n",
        "tokenizer.save_pretrained(str(adapter_dir))\n",
        "\n",
        "!cp -r {adapter_dir} /content/drive/MyDrive/distilbert_lora_adapter\n",
        "print(\"âœ… DistilBERT LoRA adapter saved to your Google Drive root (MyDrive/distilbert_lora_adapter)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctaGYFhRLk8s",
        "outputId": "b9050942-0b68-4066-a8ad-8e946658a18d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… DistilBERT LoRA adapter saved to your Google Drive root (MyDrive/distilbert_lora_adapter)\n"
          ]
        }
      ]
    }
  ]
}
